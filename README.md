# PennApps2020
PennApps Hackathon project

Co-contributors: Worked with [Kaviya Nachiappan](https://github.com/KaviyaNachiappan), [Colin Peppler](https://github.com/ColinPeppler), and [Weihao Gao](https://github.com/weihao).

Our project, Lychee-Taro (our team loves Boba tea!), allows the user to upload a picture from their device to the website, and the website will in turn play music that
corresponds to the "emotions" in that song. For example, if the user uploads a picture of a beach, the website will play "happy" music.

We used Node.js, Vue.js, Python, HMTL/CSS/Javascript, and a bit of Machine Learning (using Google's Vision API) to detect objects in the picture that would map to 
certain emotions (i.e. the sun being mapped to happy, clouds/rain being mapped to sad, etc). 
